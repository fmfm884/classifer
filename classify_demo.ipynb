{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classify_demo.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UNIkZxWUELhJi-XF49lKWpMwXXpdY3Fz","authorship_tag":"ABX9TyP2DUNaheXZjYw8vl/gLz+W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NXzjMjTBkR8H"},"source":["# 画像分類の実践\n","本稿ではオリジナルのデータセットを使用して画像分類を実践します。  ぜひソースコードを改変してより精度の高いモデルを学習できることを目標にいろいろ試してみてください。  \n","研修中ではデータセット「**車**」、「**猫**」、「**家**」の３クラス分類を行います。各クラス学習用100枚、テスト用10枚で実践します。機械学習ライブラリは**Pytorch**です。"]},{"cell_type":"markdown","metadata":{"id":"pH1Z6rkRyNxw"},"source":["### 事前準備\n","##### ・GPUの利用設定\n","ツールバーの\"**ランタイム**\"→\"**ランタイムのタイプを変更**\"→ハードウェアアクセラレータの\"**GPU**\"を選択→\"**保存**\"  \n","##### ・Google Driveのマウント\n","左にあるツールバー内の\"**ファイル**\"→\"**ドライブをマウント**\"  \n","（Google Drive上のファイルを読み書きできるようにするためにマウントを行います。）\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uQinMYrysRCn"},"source":["### 注意\n","\"Google Drive\"のMyDrive配下にzip展開した\"img_classification\"フォルダが正しく配置されていることを確認してください。配置場所が間違えていると実行できません。  \n","  \n","例：colaboratory上のファイル配置  \n","/content/drive/MyDrive ─ img_classification ─ classify_demo.ipynb  \n","　　　　　　　　　　　　　　　　　　　　└　data \n","　　　　　　　　　　　　 "]},{"cell_type":"markdown","metadata":{"id":"UByrhAeHk1pK"},"source":["# 手順１  \n","画像データセットを収集  \n","研修では「車」,「猫」,「家」の3クラス分類を行います。学習用100枚、テスト用10枚で実践します。"]},{"cell_type":"markdown","metadata":{"id":"2W6NjMwJk_7F"},"source":["# 手順２\n","画像データセットを'data'フォルダ内に配置。下記のディレクトリ階層図を参考にしてください。  \n","デフォルトでは研修で使用するデータセットが既に配置済みです。\n","  \n","data ─ train ─ car ─ ＊.jpg    \n","　　│　　  │  \n","　　│　  　├ cat ─ ＊.jpg  \n","　　│　　  │  \n","　　│　  　└ house ─ ＊.jpg    \n","　　│  \n","　  　└ test ─ car ─ ＊.jpg  \n","　　　　  　 │   \n","　　　  　　 ├ cat ─ ＊.jpg  \n","　　 　　  　│  \n","　　　  　　 └ house ─ ＊.jpg    \n"]},{"cell_type":"markdown","metadata":{"id":"zA-S3yUX0hJM"},"source":["# 手順３\n","下記のセル群を順番に実行"]},{"cell_type":"code","metadata":{"id":"H1lbNZKo9ub8"},"source":["import os\n","import copy\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import datasets, transforms, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# gpuが使用可能ならgpuを使用、不可能ならcpuを使用\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2YD8DCem2dDO"},"source":["### 学習用データセットの前処理\n","1.画像のリサイズ  \n","2.テンソル型に変換(pytorch特有の処理)  \n","3.標準化  \n","4.ミニバッチ化  "]},{"cell_type":"code","metadata":{"id":"imd4wtqZ7ouT"},"source":["# データカスタマイズセル\n","TRAIN_DIR = '/content/drive/MyDrive/img_classification/data/train'\n","BATCH_SIZE = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJEftSELxYaS"},"source":["train_transforms = transforms.Compose([\n","                                # 1.画像のリサイズ\n","                                transforms.Resize((224, 224)),\n","                                # 2.テンソル型に変換\n","                                transforms.ToTensor(),  \n","                                # 3.標準化\n","                                transforms.Normalize([0.485, 0.456, 0.406],\n","                                                     [0.229, 0.224, 0.225])\n","                                ])\n","\n","# 前処理したデータセットを読み込む\n","train_datasets = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n","\n","# 4.ミニバッチ化\n","train_loaders = DataLoader(train_datasets, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n","\n","# 学習画像の枚数を取得\n","train_sizes = len(train_datasets)\n","\n","# 学習データセットのクラスを取得\n","train_class_names = train_datasets.classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n9l1oo2xNCjj"},"source":["print(train_sizes)\n","print(train_class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Rr1hxJn2ndy"},"source":["### データの中身を確認\n","上記セルの”train_loaders”(イテレータ)に格納したデータセット(1ミニバッチ)の中身を確認します。  \n","  \n","注意：テンソル型に変換された状態なのでnumpyで次元(軸)を変換するのと、標準化されたデータを元に戻すことが必要です。  \n","  \n","1.”train_loader”から画像とラベルを順番に取り出す  \n","2.テンソル型からnumpyの型に変換  \n","3.標準化されたデータを元に戻す"]},{"cell_type":"code","metadata":{"id":"Wuksq4ML2p_A"},"source":["def tensor_to_numpy(inp):\n","  # 2.テンソル型からnumpyの型に変換\n","  inp = inp.numpy().transpose((1,2,0))\n","  # 3.標準化されたデータを元に戻す\n","  mean = np.array([0.485, 0.456, 0.406])\n","  std = np.array([0.229, 0.224, 0.225])\n","  inp = std * inp + mean\n","  inp = np.clip(inp, 0, 1)\n","  return inp\n","\n","# 1.\"train_loaders\"から画像とラベルを順番に取り出す\n","inputs, classes = next(iter(train_loaders))\n","out = torchvision.utils.make_grid(inputs)\n","\n","# imshowメソッドを実行\n","out = tensor_to_numpy(out)\n","plt.imshow(out)\n","plt.title([train_class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGGfkH_jXJ02"},"source":["### モデル　損失関数　最適化法の定義\n","転移学習のベースモデルは学習済みの**VGG16**を使用します。損失関数は**クロスエントロピー誤差**。最適化法は**MomentumSGD**を使用します。  \n","また今回は”torch.optim.lr_scheduler.StepLR”を使用して7epochごとに学習率を1/10にします。  \n","1.モデルの定義  \n","2.損失関数の定義  \n","3.最適化法の定義"]},{"cell_type":"code","metadata":{"id":"ZtYEOC2w2vE4"},"source":["# 学習カスタマイズセル\n","\n","# 1モデルの定義\n","model_ft = models.vgg16(pretrained=True)\n","num_ftrs = model_ft.classifier[6].in_features\n","# モデルの全結合層にある最終層のニューロン数をクラス数(研修では3クラス)に変更する\n","model_ft.classifier[6] = nn.Linear(num_ftrs, len(train_class_names))\n","\n","# for ResNet18 (やってみよう2)\n","#model_ft = models.resnet18(pretrained=True)\n","#num_ftrs = model_ft.fc.in_features\n","#model_ft.fc = nn.Linear(num_ftrs, len(train_class_names))\n","\n","model_ft = model_ft.to(device)\n","\n","# 2.損失関数の定義\n","criterion = nn.CrossEntropyLoss()\n","\n","# 3.最適化法の定義\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n","\n","# エポックの指定\n","NUM_EPOCHS = 2\n","\n","# 7epochごとに学習率を1/10にする(7エポック未満の場合は関係ない)\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmr0bT-c3NNX"},"source":["### 学習\n","1.モデルをトレーニングモードにする  \n","2.学習データとラベルを順番にとりだす  \n","3.勾配(微分)をリセット  \n","4.順伝播  \n","5.逆伝播  "]},{"cell_type":"code","metadata":{"id":"oqW66_ho3AaC"},"source":["# 学習メソッドを宣言\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    best_loss = 0.0\n","    lossdata = []\n","    accdata = []\n","    \n","    for epoch in tqdm(range(num_epochs)):\n","        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n","        print('-' * 10)\n","        \n","        scheduler.step()\n","\n","        # 1.モデルをトレーニングモードにする\n","        model.train()\n","\n","        running_loss = 0.0     # 損失関数の合計を保存するための変数\n","        running_corrects = 0   # 精度の合計を保存するための変数\n","            \n","        # 2.学習データとラベルを順番に取り出す\n","        for inputs, labels in train_loaders:\n","            inputs = inputs.to(device)      # 画像データを格納\n","            labels = labels.to(device)      # ラベル（教師データ）を格納\n","                \n","            # 3.勾配(微分)をリセット\n","            optimizer.zero_grad()\n","                \n","            # 4.順伝播\n","            outputs = model(inputs)      # 画像データをモデルに入力し、出力された予測データを取得\n","            _, preds = torch.max(outputs, 1)   # 予測データ(確率)の最大値を取得\n","            loss = criterion(outputs, labels)  # 予測データと教師データから誤差を取得\n","            \n","            # 5.逆伝播\n","            loss.backward()\n","            optimizer.step()   # 勾配(微分)計算\n","                \n","            # 損失関数と精度の合計を取得\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","        \n","        # エポックごとの損失関数と精度を取得\n","        epoch_loss = running_loss / train_sizes\n","        epoch_acc = running_corrects.double() / train_sizes\n","            \n","        lossdata.append(epoch_loss)\n","        accdata.append(epoch_acc)\n","\n","        if epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            # 精度が最も高いときに重みを格納\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            \n","        print('Loss: {:.4f} Acc: {:4f}'.format(epoch_loss, epoch_acc))\n","    \n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best train Acc:{:4f}'.format(best_acc))\n","\n","    # 最も精度が高かった重みを読み込む\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, lossdata, accdata\n","\n","\n","# training\n","model_ft, lossdata, accdata = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5dR06N2f3Wuk"},"source":["### モデルの保存\n","model.state_dict()で保存が可能。重みのみを保存している。"]},{"cell_type":"code","metadata":{"id":"-gOADsbu3So-"},"source":["save_path = '/content/drive/MyDrive/img_classification/models'\n","os.makedirs(save_path, exist_ok=True)\n","torch.save(model_ft.state_dict(), os.path.join(save_path, 'model.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v22y_Nlf4Xgv"},"source":["### モデルの読み込み\n","上記で重みのみを保存したモデルを読み込む際は、再度モデルを定義し直してから読み込む。"]},{"cell_type":"code","metadata":{"id":"wVpUbVnm4cx5"},"source":["# for vgg16\n","model = models.vgg16()\n","num_ftrs = model.classifier[6].in_features\n","# モデルの全結合層にある最終層のニューロン数をクラス数(研修では3クラス)に変更する\n","model.classifier[6] = nn.Linear(num_ftrs, len(train_class_names))\n","\n","# for ResNet18\n","#model = models.resnet18()\n","#num_ftrs = model.fc.in_features\n","#model.fc = nn.Linear(num_ftrs, len(train_class_names))\n","\n","model.load_state_dict(torch.load(os.path.join(save_path, 'model.pth')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dibJIi94fcj"},"source":["### 精度と損失関数のグラフ"]},{"cell_type":"code","metadata":{"id":"xAYmuNAD4hlO"},"source":["fig = plt.figure()\n","\n","# 横軸の設定\n","x = list(range(NUM_EPOCHS))\n","\n","# 精度グラフ\n","np_acc = np.array(accdata[:NUM_EPOCHS])\n","ax_acc = fig.add_subplot(1, 2, 1, title='train_acc', ylim=(0,1))\n","ax_acc.plot(x, np_acc)\n","\n","# 損失関数グラフ\n","np_loss = np.array(lossdata[:NUM_EPOCHS])\n","ax_loss = fig.add_subplot(1, 2, 2, title='train_loss', ylim=(0,1))\n","ax_loss.plot(x, np_loss)\n","\n","# グラフ出力\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0ptsHuZ46ea"},"source":["### テスト用データセットの前処理\n","1.画像のリサイズ  \n","2.テンソル型に変換(pytorch特有の処理)  \n","3.標準化  \n","4.ミニバッチ化  "]},{"cell_type":"code","metadata":{"id":"1nE2qtv6pn0e"},"source":["# 学習用データカスタマイズセル\n","TEST_DIR = '/content/drive/MyDrive/img_classification/data/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rmfg566S47Du"},"source":["TEST_DIR = os.path.join(TEST_DIR)\n","transform = transforms.Compose([\n","                    # 1.画像のリサイズ\n","                    transforms.Resize((224,224)),\n","                    # 2.テンソル型に変換\n","                    transforms.ToTensor(),\n","                    # 3.標準化 \n","                    transforms.Normalize([0.485, 0.456, 0.406],\n","                                        [0.229, 0.224, 0.225])\n","                    ])\n","\n","# 前処理したデータセットを読み込む\n","test_datasets = datasets.ImageFolder(TEST_DIR, transform=transform)\n","\n","# 4.ミニバッチ化\n","test_loaders = DataLoader(test_datasets, batch_size=1, shuffle=True, num_workers=0)\n","\n","# テスト用画像の枚数を取得\n","test_sizes = len(test_datasets)\n","test_class_names = test_datasets.classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNzq-H0PdHjL"},"source":["### テスト\n","学習済みモデルを使って推論を行います。  \n","1.モデルを評価モードにする  \n","2.テストデータとラベルを順番に取り出す  \n","3.テストデータを読み込み、予測データを取得  \n","4.予測データの最大値を予測結果とする"]},{"cell_type":"code","metadata":{"id":"vqFXBx2M5FfK"},"source":["def visualize_model(model, num_images=0):\n","    # 1.モデルを評価モードにする\n","    model.eval()\n","    fig = plt.figure()\n","    acc = 0\n","    \n","    with torch.no_grad():\n","        # 2.テストデータとラベルを順番に取り出す\n","        for i, (inputs, labels) in enumerate(test_loaders):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            # 3.テストデータを読み込み、予測データを取得\n","            outputs = model(inputs)\n","\n","            # 4.予測データの最大値を予測結果とする\n","            _, preds = torch.max(outputs, 1)\n","\n","            print('predicted: {} ,  label: {}'.format(train_class_names[preds], test_class_names[labels]))\n","            plt.imshow(tensor_to_numpy(inputs.cpu().data[0]))\n","            plt.show()\n","            \n","            if test_class_names[preds] == test_class_names[labels]:\n","                acc += 1\n","\n","            print('-' * 60)\n","        print('{}枚中、{}枚正解'.format(str(num_images), str(acc)))\n","        model.train()\n","\n","\n","visualize_model(model_ft, len(test_loaders))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8V8uAZ9SrRi"},"source":["## やってみよう  \n","####１．自分の好きなオリジナルデータセットを使って画像分類を実践してみよう  \n","オリジナルデータセットを使って実践する方法は本稿の**手順1**と**手順2**で説明済みです。  \n","**<補足>**  \n","データセットは画像検索で集めることが可能ですが一枚ずつ保存していては大変です。Google Chromeユーザ限定の紹介になってしまいますが、**ImageDownloader**というChromeの拡張機能を使ってデータを集めることを推奨します。**ImageDownloader**のインストール方法は[こちら](https://chrome.google.com/webstore/detail/image-downloader/cnpniohnfphhjihaiiggeabnkjhpaldj?hl=ja&)  \n","  \n","####２．転移学習のベースモデルを**VGG16**から**ResNet18**に変更して学習させてみよう  \n","VGG16とResNet18の両方の結果を比較してみてください。研修で利用した「猫」「車」「家」の3クラス分類では難易度が低すぎるため違いが分かりにくいですが、10クラス以上の分類や細かな種類の分類問題を学習させてみると違いが見えてくると思います。  \n","ソースコードの改変箇所は本稿の**モデル 損失関数 最適化法の定義**にある**学習カスタマイズセル**の中身です。L4,5,7をコメントアウトして、L10,11,12の**#**を削除するとベースモデルをResNet18に変更できます。"]}]}